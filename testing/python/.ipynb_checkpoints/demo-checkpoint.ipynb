{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dynamic module does not define module export function (PyInit__caffe)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6086f8ed1469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caffe/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_solver_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_multiprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_nccl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/caffe/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dynamic module does not define module export function (PyInit__caffe)"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0,'/home/chinmay/caffe/python')\n",
    "\n",
    "import cv2 as cv \n",
    "import numpy as np\n",
    "import scipy\n",
    "import PIL.Image\n",
    "import math\n",
    "import caffe\n",
    "import time\n",
    "from config_reader import config_reader\n",
    "import util\n",
    "import copy\n",
    "import matplotlib\n",
    "#%matplotlib inline\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_image = '../sample_image/ski.jpg'\n",
    "#test_image = '../sample_image/upper.jpg'\n",
    "#test_image = '../sample_image/upper2.jpg'\n",
    "oriImg = cv.imread(test_image) # B,G,R order\n",
    "f = plt.imshow(oriImg[:,:,[2,1,0]]) # reorder it before displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param, model = config_reader()\n",
    "multiplier = [x * model['boxsize'] / oriImg.shape[0] for x in param['scale_search']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if param['use_gpu']: \n",
    "    caffe.set_mode_gpu()\n",
    "    caffe.set_device(param['GPUdeviceNumber']) # set to your device!\n",
    "else:\n",
    "    caffe.set_mode_cpu()\n",
    "net = caffe.Net(model['deployFile'], model['caffemodel'], caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "heatmap_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 19))\n",
    "paf_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 38))\n",
    "# first figure shows padded images\n",
    "f, axarr = plt.subplots(1, len(multiplier))\n",
    "f.set_size_inches((20, 5))\n",
    "# second figure shows heatmaps\n",
    "f2, axarr2 = plt.subplots(1, len(multiplier))\n",
    "f2.set_size_inches((20, 5))\n",
    "# third figure shows PAFs\n",
    "f3, axarr3 = plt.subplots(2, len(multiplier))\n",
    "f3.set_size_inches((20, 10))\n",
    "\n",
    "for m in range(len(multiplier)):\n",
    "    scale = multiplier[m]\n",
    "    imageToTest = cv.resize(oriImg, (0,0), fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "    imageToTest_padded, pad = util.padRightDownCorner(imageToTest, model['stride'], model['padValue'])\n",
    "    print imageToTest_padded.shape\n",
    "    \n",
    "    axarr[m].imshow(imageToTest_padded[:,:,[2,1,0]])\n",
    "    axarr[m].set_title('Input image: scale %d' % m)\n",
    "\n",
    "    net.blobs['data'].reshape(*(1, 3, imageToTest_padded.shape[0], imageToTest_padded.shape[1]))\n",
    "    #net.forward() # dry run\n",
    "    net.blobs['data'].data[...] = np.transpose(np.float32(imageToTest_padded[:,:,:,np.newaxis]), (3,2,0,1))/256 - 0.5;\n",
    "    start_time = time.time()\n",
    "    output_blobs = net.forward()\n",
    "    print('At scale %d, The CNN took %.2f ms.' % (m, 1000 * (time.time() - start_time)))\n",
    "\n",
    "    # extract outputs, resize, and remove padding\n",
    "    heatmap = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[1]].data), (1,2,0)) # output 1 is heatmaps\n",
    "    heatmap = cv.resize(heatmap, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
    "    heatmap = heatmap[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
    "    heatmap = cv.resize(heatmap, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n",
    "    \n",
    "    paf = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[0]].data), (1,2,0)) # output 0 is PAFs\n",
    "    paf = cv.resize(paf, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
    "    paf = paf[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
    "    paf = cv.resize(paf, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n",
    "    \n",
    "    # visualization\n",
    "    axarr2[m].imshow(oriImg[:,:,[2,1,0]])\n",
    "    ax2 = axarr2[m].imshow(heatmap[:,:,3], alpha=.5) # right wrist\n",
    "    axarr2[m].set_title('Heatmaps (Rwri): scale %d' % m)\n",
    "    \n",
    "    axarr3.flat[m].imshow(oriImg[:,:,[2,1,0]])\n",
    "    ax3x = axarr3.flat[m].imshow(paf[:,:,16], alpha=.5) # right elbow\n",
    "    axarr3.flat[m].set_title('PAFs (x comp. of Rwri to Relb): scale %d' % m)\n",
    "    axarr3.flat[len(multiplier) + m].imshow(oriImg[:,:,[2,1,0]])\n",
    "    ax3y = axarr3.flat[len(multiplier) + m].imshow(paf[:,:,17], alpha=.5) # right wrist\n",
    "    axarr3.flat[len(multiplier) + m].set_title('PAFs (y comp. of Relb to Rwri): scale %d' % m)\n",
    "    \n",
    "    heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n",
    "    paf_avg = paf_avg + paf / len(multiplier)\n",
    "\n",
    "f2.subplots_adjust(right=0.93)\n",
    "cbar_ax = f2.add_axes([0.95, 0.15, 0.01, 0.7])\n",
    "_ = f2.colorbar(ax2, cax=cbar_ax)\n",
    "\n",
    "f3.subplots_adjust(right=0.93)\n",
    "cbar_axx = f3.add_axes([0.95, 0.57, 0.01, 0.3])\n",
    "_ = f3.colorbar(ax3x, cax=cbar_axx)\n",
    "cbar_axy = f3.add_axes([0.95, 0.15, 0.01, 0.3])\n",
    "_ = f3.colorbar(ax3y, cax=cbar_axy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look on those averaged heatmaps and PAFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(oriImg[:,:,[2,1,0]])\n",
    "plt.imshow(heatmap_avg[:,:,2], alpha=.5)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "cax = matplotlib.pyplot.gca()\n",
    "fig.set_size_inches(20, 20)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "cbar_ax = fig.add_axes([0.95, 0.15, 0.01, 0.7])\n",
    "_ = fig.colorbar(ax2, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import ma\n",
    "U = paf_avg[:,:,16] * -1\n",
    "V = paf_avg[:,:,17]\n",
    "X, Y = np.meshgrid(np.arange(U.shape[1]), np.arange(U.shape[0]))\n",
    "M = np.zeros(U.shape, dtype='bool')\n",
    "M[U**2 + V**2 < 0.5 * 0.5] = True\n",
    "U = ma.masked_array(U, mask=M)\n",
    "V = ma.masked_array(V, mask=M)\n",
    "\n",
    "# 1\n",
    "plt.figure()\n",
    "plt.imshow(oriImg[:,:,[2,1,0]], alpha = .5)\n",
    "s = 5\n",
    "Q = plt.quiver(X[::s,::s], Y[::s,::s], U[::s,::s], V[::s,::s], \n",
    "               scale=50, headaxislength=4, alpha=.5, width=0.001, color='r')\n",
    "\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "print heatmap_avg.shape\n",
    "\n",
    "#plt.imshow(heatmap_avg[:,:,2])\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "all_peaks = []\n",
    "peak_counter = 0\n",
    "\n",
    "for part in range(19-1):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    map_ori = heatmap_avg[:,:,part]\n",
    "    map = gaussian_filter(map_ori, sigma=3)\n",
    "    \n",
    "    map_left = np.zeros(map.shape)\n",
    "    map_left[1:,:] = map[:-1,:]\n",
    "    map_right = np.zeros(map.shape)\n",
    "    map_right[:-1,:] = map[1:,:]\n",
    "    map_up = np.zeros(map.shape)\n",
    "    map_up[:,1:] = map[:,:-1]\n",
    "    map_down = np.zeros(map.shape)\n",
    "    map_down[:,:-1] = map[:,1:]\n",
    "    \n",
    "    peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > param['thre1']))\n",
    "    peaks = zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]) # note reverse\n",
    "    peaks_with_score = [x + (map_ori[x[1],x[0]],) for x in peaks]\n",
    "    id = range(peak_counter, peak_counter + len(peaks))\n",
    "    peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
    "\n",
    "    all_peaks.append(peaks_with_score_and_id)\n",
    "    peak_counter += len(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find connection in the specified sequence, center 29 is in the position 15\n",
    "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "# the middle joints heatmap correpondence\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22], \\\n",
    "          [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], \\\n",
    "          [55,56], [37,38], [45,46]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connection_all = []\n",
    "special_k = []\n",
    "mid_num = 10\n",
    "\n",
    "for k in range(len(mapIdx)):\n",
    "    score_mid = paf_avg[:,:,[x-19 for x in mapIdx[k]]]\n",
    "    candA = all_peaks[limbSeq[k][0]-1]\n",
    "    candB = all_peaks[limbSeq[k][1]-1]\n",
    "    nA = len(candA)\n",
    "    nB = len(candB)\n",
    "    indexA, indexB = limbSeq[k]\n",
    "    if(nA != 0 and nB != 0):\n",
    "        connection_candidate = []\n",
    "        for i in range(nA):\n",
    "            for j in range(nB):\n",
    "                vec = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                norm = math.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
    "                vec = np.divide(vec, norm)\n",
    "                \n",
    "                startend = zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), \\\n",
    "                               np.linspace(candA[i][1], candB[j][1], num=mid_num))\n",
    "                \n",
    "                vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] \\\n",
    "                                  for I in range(len(startend))])\n",
    "                vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] \\\n",
    "                                  for I in range(len(startend))])\n",
    "\n",
    "                score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*oriImg.shape[0]/norm-1, 0)\n",
    "                criterion1 = len(np.nonzero(score_midpts > param['thre2'])[0]) > 0.8 * len(score_midpts)\n",
    "                criterion2 = score_with_dist_prior > 0\n",
    "                if criterion1 and criterion2:\n",
    "                    connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
    "\n",
    "        connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "        connection = np.zeros((0,5))\n",
    "        for c in range(len(connection_candidate)):\n",
    "            i,j,s = connection_candidate[c][0:3]\n",
    "            if(i not in connection[:,3] and j not in connection[:,4]):\n",
    "                connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
    "                if(len(connection) >= min(nA, nB)):\n",
    "                    break\n",
    "\n",
    "        connection_all.append(connection)\n",
    "    else:\n",
    "        special_k.append(k)\n",
    "        connection_all.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# last number in each row is the total parts number of that person\n",
    "# the second last number in each row is the score of the overall configuration\n",
    "subset = -1 * np.ones((0, 20))\n",
    "candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "for k in range(len(mapIdx)):\n",
    "    if k not in special_k:\n",
    "        partAs = connection_all[k][:,0]\n",
    "        partBs = connection_all[k][:,1]\n",
    "        indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "\n",
    "        for i in range(len(connection_all[k])): #= 1:size(temp,1)\n",
    "            found = 0\n",
    "            subset_idx = [-1, -1]\n",
    "            for j in range(len(subset)): #1:size(subset,1):\n",
    "                if subset[j][indexA] == partAs[i] or subset[j][indexB] == partBs[i]:\n",
    "                    subset_idx[found] = j\n",
    "                    found += 1\n",
    "            \n",
    "            if found == 1:\n",
    "                j = subset_idx[0]\n",
    "                if(subset[j][indexB] != partBs[i]):\n",
    "                    subset[j][indexB] = partBs[i]\n",
    "                    subset[j][-1] += 1\n",
    "                    subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "            elif found == 2: # if found 2 and disjoint, merge them\n",
    "                j1, j2 = subset_idx\n",
    "                print \"found = 2\"\n",
    "                membership = ((subset[j1]>=0).astype(int) + (subset[j2]>=0).astype(int))[:-2]\n",
    "                if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
    "                    subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                    subset[j1][-2:] += subset[j2][-2:]\n",
    "                    subset[j1][-2] += connection_all[k][i][2]\n",
    "                    subset = np.delete(subset, j2, 0)\n",
    "                else: # as like found == 1\n",
    "                    subset[j1][indexB] = partBs[i]\n",
    "                    subset[j1][-1] += 1\n",
    "                    subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "\n",
    "            # if find no partA in the subset, create a new subset\n",
    "            elif not found and k < 17:\n",
    "                row = -1 * np.ones(20)\n",
    "                row[indexA] = partAs[i]\n",
    "                row[indexB] = partBs[i]\n",
    "                row[-1] = 2\n",
    "                row[-2] = sum(candidate[connection_all[k][i,:2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                subset = np.vstack([subset, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some rows of subset which has few parts occur\n",
    "deleteIdx = [];\n",
    "for i in range(len(subset)):\n",
    "    if subset[i][-1] < 4 or subset[i][-2]/subset[i][-1] < 0.4:\n",
    "        deleteIdx.append(i)\n",
    "subset = np.delete(subset, deleteIdx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize\n",
    "colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "cmap = matplotlib.cm.get_cmap('hsv')\n",
    "\n",
    "canvas = cv.imread(test_image) # B,G,R order\n",
    "\n",
    "for i in range(18):\n",
    "    rgba = np.array(cmap(1 - i/18. - 1./36))\n",
    "    rgba[0:3] *= 255\n",
    "    for j in range(len(all_peaks[i])):\n",
    "        cv.circle(canvas, all_peaks[i][j][0:2], 4, colors[i], thickness=-1)\n",
    "\n",
    "to_plot = cv.addWeighted(oriImg, 0.3, canvas, 0.7, 0)\n",
    "plt.imshow(to_plot[:,:,[2,1,0]])\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize 2\n",
    "stickwidth = 4\n",
    "\n",
    "for i in range(17):\n",
    "    for n in range(len(subset)):\n",
    "        index = subset[n][np.array(limbSeq[i])-1]\n",
    "        if -1 in index:\n",
    "            continue\n",
    "        cur_canvas = canvas.copy()\n",
    "        Y = candidate[index.astype(int), 0]\n",
    "        X = candidate[index.astype(int), 1]\n",
    "        mX = np.mean(X)\n",
    "        mY = np.mean(Y)\n",
    "        length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "        angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "        polygon = cv.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "        cv.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "        canvas = cv.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "        \n",
    "plt.imshow(canvas[:,:,[2,1,0]])\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(12, 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
